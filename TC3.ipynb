{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "764c0079-b32a-4f09-b4f1-f2929d7d1d88",
   "metadata": {},
   "source": [
    "# Trabalho Computacional 3. Rede Convolucional e Transfer Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c455605d-91cb-4c2e-a4a8-76610ec47fc5",
   "metadata": {},
   "source": [
    "### Nome: Antonio Leonardo Souto Gomes\n",
    "### Matrícula: 211027607"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4675aeb4-cad6-46fe-9131-3d90fee6553a",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0c2eef-0397-4f80-9c98-79f7e1ac5ff2",
   "metadata": {},
   "source": [
    "Este trabalho computacional explora o uso de redes neurais para classificação de imagens, utilizando a base de dados CIFAR10. O estudo abrange desde a implementação de um Perceptron Multicamadas (MLP) \"do zero\" até a aplicação de técnicas avançadas como o transfer learning com uma Rede Neural Convolucional (CNN) pré-treinada, especificamente a VGG16.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109e9ff0-1105-463b-bab2-af65b4ca48a1",
   "metadata": {},
   "source": [
    "## Implementação(MLP from scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbfe1f6-65e1-4504-bc53-575ae4db88e0",
   "metadata": {},
   "source": [
    "O primeiro passo é o de importar algumas importantes bibliotecas python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c931471d-7037-4095-a892-6bc8b046caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "from torchmetrics.functional import accuracy\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning import Trainer\n",
    "from torchvision.models import vgg16\n",
    "from torchvision.models import mobilenet_v3_large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ead539-5233-466d-a2da-a559138d1c1c",
   "metadata": {},
   "source": [
    "Inicialmente, aborda-se a preparação dos dados da base CIFAR10, que consiste em 60.000 imagens 32x32 coloridas de 10 categorias distintas. As imagens são redimensionadas para 224x224 pixels e a base é dividida em conjuntos de treinamento (40.000 exemplos), validação (10.000 exemplos) e teste (10.000 exemplos), com seus respectivos DataLoaders já configurados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce486629-c49a-4249-b0f5-bde022584285",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10():  #@save    \n",
    "    def __init__(self, root, resize=(224, 224)):    \n",
    "        trans = transforms.Compose([transforms.Resize(resize),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        self.train = torchvision.datasets.CIFAR10(\n",
    "            root=root, train=True, transform=trans, download=True)\n",
    "        train_set_size = int(len(self.train) * 0.8)\n",
    "        valid_set_size = len(self.train) - train_set_size\n",
    "        seed = torch.Generator().manual_seed(42)\n",
    "        self.train, self.val = torch.utils.data.random_split(self.train, [train_set_size, valid_set_size], generator=seed)\n",
    "        self.test = torchvision.datasets.CIFAR10(\n",
    "            root=root, train=False, transform=trans, download=True)\n",
    "        \n",
    "dataset = CIFAR10(root=\"./data/\")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset.train, batch_size=64, shuffle=True, num_workers=6,persistent_workers=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(dataset.val, batch_size=64, shuffle=False, num_workers=6, persistent_workers=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset.test, batch_size=64, shuffle=False, num_workers=6, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f292e18b-2b01-4410-8e30-021cd3f218db",
   "metadata": {},
   "source": [
    "Em seguida, o trabalho foca no treinamento de um Perceptron Multicamadas (MLP) com duas camadas escondidas. A estrutura de treinamento e avaliação do modelo é facilitada pela biblioteca PyTorch Lightning, através da classe LightModel. Esta classe encapsula as etapas de treinamento (training_step), validação (validation_step) e teste (test_step), além de configurar o otimizador Adam. A training_step e validation_step calculam a loss de entropia cruzada, enquanto a test_step também calcula a acurácia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b35994c4-04fb-41e0-8e46-124aacc988be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightModel(pl.LightningModule):\n",
    "    def __init__(self, model, lr=1e-5, weight_decay=0.0,l1_lambda=0.0):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.l1_lambda = l1_lambda\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        X, y = batch\n",
    "        y_hat = self.model(X)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y)\n",
    "        if self.l1_lambda > 0:\n",
    "            l1_penalty = sum(torch.norm(param, 1) for param in self.model.parameters())\n",
    "            loss += self.l1_lambda * l1_penalty\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        X, y = batch\n",
    "        y_hat = self.model(X)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        X, y = batch\n",
    "        y_hat = self.model(X)\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        acc = accuracy(preds, y, task=\"multiclass\", num_classes=10)\n",
    "        self.log(\"test_acc\", acc)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y)        \n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a1c42-6da1-453d-aaad-883dbfe7e195",
   "metadata": {},
   "source": [
    "Em seguida, o trabalho foca no treinamento de um Perceptron Multicamadas (MLP) com duas camadas escondidas. A arquitetura deste MLP, definida em arch, é composta por uma camada Flatten para transformar as imagens 2D em vetores 1D, seguida por duas camadas densas (nn.Linear) com ativação ReLU, e uma camada de saída final com 10 neurônios para as classes do CIFAR10. Este modelo é então encapsulado pela classe LightModel do PyTorch Lightning para facilitar o treinamento e avaliação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8588c82-51e7-48d8-9b44-eab78bcce2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = nn.Sequential(\n",
    "\t\t\tnn.Flatten(),\n",
    "\t\t\tnn.Linear(3*224*224,256),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(256,64),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(64,10)\t\n",
    "\t)\n",
    "\n",
    "mlp = LightModel(arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07db21a-dc19-49ca-818f-5bf2180a7a02",
   "metadata": {},
   "source": [
    "Em seguida, para controlar o sobreajuste e otimizar o processo de treinamento, a técnica de early stopping é implementada. Utilizando o EarlyStopping do PyTorch Lightning, o treinamento é monitorado pela loss de validação (val_loss). Se essa métrica não apresentar melhoria (diminuição mínima de 0.001) por 5 épocas consecutivas, o treinamento é automaticamente interrompido. Um Trainer do PyTorch Lightning é então configurado com este callback de early stopping e um limite máximo de 50 épocas, sendo responsável por coordenar o processo de ajuste do modelo mlp com os dataloaders de treinamento e validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5d7128-2132-48a4-8d47-e65d43de81dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=5,          \n",
    "    mode='min',          \n",
    "    min_delta=0.001      \n",
    ")\n",
    "\n",
    "trainer = Trainer(callbacks=[early_stopping], max_epochs=10)\n",
    "trainer.fit(model=mlp, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a408aea-67ef-44f6-9d92-448fe72a03de",
   "metadata": {},
   "source": [
    "Por fim, para avaliar o desempenho final do modelo treinado, o trainer é utilizado para executar a avaliação no conjunto de teste. O método trainer.test() é chamado com o modelo mlp e o test_dataloader, que irá calcular métricas como a loss e a acurácia no conjunto de dados não visto durante o treinamento e validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcb90ce5-2fa7-4478-8a5e-d51449effa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55bf45a12164015b1ec7c0b95f5c0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                       | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5134000182151794     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.3991731405258179     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5134000182151794    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.3991731405258179    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.5134000182151794, 'test_loss': 1.3991731405258179}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=mlp, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce3e7b1-fa97-45c9-bb73-b9b66e35e4e1",
   "metadata": {},
   "source": [
    "## Implementação(VGG-16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73346e6-311c-4be6-a7ed-d5b2e5f6db00",
   "metadata": {},
   "source": [
    "Após as etapas iniciais, o trabalho avança para a aplicação do transfer learning utilizando a rede VGG16. Neste estágio, uma VGG16 pré-treinada na base ImageNet é empregada como um extrator de características fixo, com seus parâmetros de convolução congelados para evitar o retreinamento. O bloco classificador original da VGG16 é então substituído por um novo Perceptron Multicamadas (MLP), personalizado para as 10 classes da base de dados CIFAR10. Somente os pesos deste novo classificador são treinados, demonstrando como o conhecimento pré-existente de grandes Redes Neurais Convolucionais (CNNs) pode ser eficientemente adaptado e reutilizado para problemas específicos de classificação de imagens, prometendo um desempenho superior ao MLP treinado \"do zero\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75a61867-60e0-4a90-865a-2844f625c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = vgg16(weights=\"DEFAULT\", progress=True)\n",
    "\n",
    "for param in vgg16_model.parameters():\n",
    "\tparam.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efb5bcf-34f0-402e-834e-d7be39c5855b",
   "metadata": {},
   "source": [
    "O trecho de código demonstra a customização do classificador de uma rede VGG16 pré-treinada para uma tarefa específica de classificação de imagens. O vgg16_model.classifier original é substituído por uma nova sequência de camadas. Esta nova sequência começa com nn.Flatten(), responsável por transformar a saída do avgpool (que é de 7×7×512 características) em um vetor unidimensional. Em seguida, uma camada nn.Linear mapeia essas 25088 características para 50 neurônios, seguida por uma função de ativação nn.ReLU(). Outra camada nn.Linear então projeta de 50 para 20 neurônios, novamente seguida por uma nn.ReLU(). Por fim, uma camada nn.Linear final com 10 neurônios é definida, correspondendo às 10 classes de saída do CIFAR10. O vgg16_model modificado é então encapsulado por LightModel, preparando-o para o treinamento onde apenas os parâmetros do novo classificador serão ajustados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a279637-d6ad-4704-a74e-a267a8a68807",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model.classifier = nn.Sequential(\n",
    "    nn.Flatten(),          \n",
    "    nn.Linear(7*7*512, 50),  \n",
    "    nn.ReLU(),             \n",
    "    nn.Linear(50, 20),     \n",
    "    nn.ReLU(),             \n",
    "    nn.Linear(20, 10)      \n",
    ")\n",
    "\n",
    "vgg_transfer_model = LightModel(vgg16_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03a7cd1-20ae-42a7-ba0d-ca41ffb5fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=3,          \n",
    "    mode='min',          \n",
    "    min_delta=0.001      \n",
    ")\n",
    "\n",
    "trainer = Trainer(accelerator='gpu', devices=1, callbacks=[early_stopping], max_epochs=5)\n",
    "trainer.fit(model=vgg_transfer_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c14419e4-533a-4da9-b833-434b4999a847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be8d397e0a14207bb45ba86b10bbe2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                       | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8030999898910522     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6667813062667847     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8030999898910522    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6667813062667847    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.8030999898910522, 'test_loss': 0.6667813062667847}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=vgg_transfer_model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d231de0e-04ed-4403-9ccf-cf3c0a365663",
   "metadata": {},
   "source": [
    "### Adcionando regularização L1 e L2 ao modelo VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d081f3-d986-4e18-ac40-a394e18254d1",
   "metadata": {},
   "source": [
    "A regularização é uma técnica essencial para evitar overfitting em modelos de aprendizado profundo, especialmente em arquiteturas grandes como o VGG16, que possui milhões de parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ff2164e-31b1-4a24-893c-ed19d9e39922",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model_L1L2 = vgg16(weights=\"DEFAULT\", progress=True)\n",
    "\n",
    "for param in vgg16_model_L1L2.parameters():\n",
    "\tparam.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ad146c-9297-4a29-85d9-8e09ca3962af",
   "metadata": {},
   "source": [
    "A regularização L2 adiciona uma penalização proporcional ao quadrado dos pesos (∑w²) na função de custo. No PyTorch, isso é facilmente aplicada via parâmetro weight_decay do otimizador. Esse método incentiva os pesos a serem pequenos, promovendo modelos mais simples e melhorando a generalização.\n",
    "Já a regularização L1 penaliza a soma dos valores absolutos dos pesos (∑|w|). Ela tende a gerar pesos exatamente zero, promovendo esparsidade no modelo, o que pode ser útil para simplificar a rede e interpretar quais neurônios são mais importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82cc8e97-cc75-4841-b2fe-20c5593e91d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model_L1L2.classifier = nn.Sequential(\n",
    "    nn.Flatten(),          \n",
    "    nn.Linear(7*7*512, 50),  \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 20),     \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)      \n",
    ")\n",
    "\n",
    "vgg_L1L2_transfer_model = LightModel(vgg16_model_L1L2, weight_decay=1e-4, l1_lambda=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582006b1-8ed7-4e94-b7e0-3c89fb22da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(accelerator='gpu',devices=1,max_epochs=5)\n",
    "trainer.fit(model=vgg_L1L2_transfer_model,train_dataloaders=train_dataloader,val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60d80327-3450-4b51-89f1-76de765d5910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba49bbfffdd141e3b93db2bf127bdd30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                       | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8015000224113464     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6867914795875549     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8015000224113464    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6867914795875549    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.8015000224113464, 'test_loss': 0.6867914795875549}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=vgg_L1L2_transfer_model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f42fce6-9db7-499d-896a-e8eba44ec3a8",
   "metadata": {},
   "source": [
    "O VGG16 é uma rede profunda com muitas camadas e parâmetros, o que aumenta o risco de overfitting. Aplicar regularização L2 (weight decay) é uma prática comum para melhorar a robustez do modelo. A L1 pode ser usada para incentivar esparsidade, embora seja menos frequente em redes convolucionais profundas.\n",
    "\n",
    "Combinando essas regularizações e outras técnicas como Dropout, conseguimos controlar melhor o aprendizado do VGG16 e alcançar melhores resultados em tarefas de visão computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffad322-2a08-4d6e-b150-adaa562864b2",
   "metadata": {},
   "source": [
    "### Adcionando Dropout ao modelo VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc923e9-8db3-4919-921b-c05f89e07e5c",
   "metadata": {},
   "source": [
    "O Dropout é uma técnica de regularização que ajuda a evitar o overfitting em redes neurais profundas, como o VGG16, que possuem muitos parâmetros e podem facilmente memorizar os dados de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e958ece4-e08b-4d7e-bc99-568f6ff77ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model_drop = vgg16(weights=\"DEFAULT\", progress=True)\n",
    "\n",
    "for param in vgg16_model_drop.parameters():\n",
    "\tparam.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752e53ed-40a1-4b02-82ea-5fa55e376e94",
   "metadata": {},
   "source": [
    "Durante o treinamento, o Dropout desliga aleatoriamente uma porcentagem dos neurônios em cada camada (normalmente entre 20% e 50%). Isso força a rede a não depender excessivamente de neurônios específicos, tornando o modelo mais robusto e capaz de generalizar melhor para dados novos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1afa3838-1fad-473b-898a-abdb2e630407",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model_drop.classifier = nn.Sequential(\n",
    "    nn.Flatten(),          \n",
    "    nn.Linear(7*7*512, 50),  \n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(50, 20),     \n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Linear(20, 10)      \n",
    ")\n",
    "\n",
    "vgg_drop_transfer_model = LightModel(vgg16_model_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5fc74c-468f-4698-b0f5-881bab4e3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(accelerator='gpu', devices=1, max_epochs=5)\n",
    "trainer.fit(model=vgg_drop_transfer_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d313e98-7205-4e1a-947d-e05575ac4e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e3ba3ba1424d5d8b469ae28e5ffa86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                       | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7663000226020813     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0494647026062012     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7663000226020813    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0494647026062012    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.7663000226020813, 'test_loss': 1.0494647026062012}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=vgg_drop_transfer_model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7125ea-f10a-4c60-8de7-cd45a5492c33",
   "metadata": {},
   "source": [
    "No VGG16 original, o Dropout é aplicado principalmente nas camadas totalmente conectadas (fully connected) no final da rede. Isso ajuda a reduzir a co-adaptação dos neurônios e melhora o desempenho em tarefas de classificação de imagens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e23084b-010d-48ee-a3b9-c1bfd359c493",
   "metadata": {},
   "source": [
    "## Implementação(MobileNetV3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ffbe93-138f-47d5-8927-d2a5b0dfba3a",
   "metadata": {},
   "source": [
    "O MobileNetV3 é uma arquitetura de rede neural convolucional desenvolvida para ser eficiente e leve, especialmente voltada para dispositivos com recursos limitados, como smartphones e dispositivos IoT. Ela combina técnicas modernas como convoluções separáveis por profundidade (depthwise separable convolutions), módulos de atenção (SE blocks) e busca neural automatizada para otimizar o desempenho e a velocidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd15ee67-2f55-48dc-bdf7-422a748ec8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model = mobilenet_v3_large(weights=\"DEFAULT\", progress=True)\n",
    "\n",
    "for param in mobilenet_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "088b7064-6bc6-4a33-8c92-b30f6e39a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model.classifier = nn.Sequential(\n",
    "    nn.Linear(mobilenet_model.classifier[0].in_features, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0931813-3ce3-45b7-9800-596d1e73b2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_transfer_model = LightModel(mobilenet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14520041-5b4d-40e4-bda0-1c00bd1158bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min',\n",
    "    min_delta=0.001\n",
    ")\n",
    "\n",
    "trainer = Trainer(accelerator='gpu',devices=1,callbacks=[early_stopping],max_epochs=50)\n",
    "trainer.fit(model=mobilenet_transfer_model,train_dataloaders=train_dataloader,val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33081121-7336-4e27-8363-3ca24540805a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb16225b176b4f50a9c4663978cd8f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                       | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7414000034332275     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7419145703315735     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7414000034332275    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7419145703315735    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.7414000034332275, 'test_loss': 0.7419145703315735}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=mobilenet_transfer_model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a5a743-0ec5-4e90-90b0-74c0136b08be",
   "metadata": {},
   "source": [
    "# Conclusão "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ebca73-d25e-4531-89f0-5596bd0bdce3",
   "metadata": {},
   "source": [
    "Este trabalho computacional foi fundamental para a familiarização e aprimoramento no uso de diversas ferramentas essenciais no desenvolvimento de modelos de aprendizado profundo. Exploramos na prática como essas ferramentas influenciam o desempenho dos modelos. A biblioteca PyTorch Lightning, em particular, mostrou-se bastante eficiente ao simplificar e organizar o processo de treinamento, oferecendo diversas facilidades.\n",
    "\n",
    "Além disso, aprofundamos nosso entendimento tanto na construção de uma MLP do zero quanto na utilização de arquiteturas pré-treinadas, o que nos permitiu observar diretamente o impacto dessas escolhas no desempenho final dos modelos. Por fim, experimentamos diferentes técnicas de regularização, demonstrando como elas contribuem para o aprimoramento do treinamento e a melhora da capacidade de generalização das redes neurais."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
